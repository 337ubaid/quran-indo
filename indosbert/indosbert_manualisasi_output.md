# Query
=== Tokenisasi ===
Teks input      : apa itu jalan yang lurus
Token/subword   : ['[CLS]', 'apa', 'itu', 'jalan', 'yang', 'lurus', '[SEP]']
Token IDs       : [2, 387, 137, 795, 34, 5971, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 7]) → [1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 7, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [ 0.4061,  0.0227,  0.0597,  0.5108, -0.3708, -0.0151, -0.4917,  0.7308,
         -0.1104,  0.1829, -0.0098, -0.2261, -0.0127, -0.3909,  0.2944, -0.4739,
          0.5531, -0.2437, -0.3850,  0.0153,  0.6686,  0.2333, -0.6239, -0.0505,
          0.2023, -0.0536, -0.4751, -0.3816, -0.2089,  0.2826,  0.0441, -0.1109,
          0.2169,  0.0056,  0.1678, -0.6925,  0.6639, -0.4291, -0.6413, -0.3301,
          0.6959,  0.6128, -0.2334,  0.4179, -0.5940, -0.0761, -0.1885,  0.2112,
          0.2283, -0.3526, -0.2048, -0.2301, -0.3591,  0.1868,  0.2379, -0.1126,
         -0.7065, -0.2864, -0.4721,  0.1247,  0.6567,  0.6085, -0.5932, -0.6217,
          0.3485, -0.5167, -0.1892, -0.4659, -0.1667,  0.5045,  0.2967, -0.2447,
          0.8142,  0.6737,  0.1414,  0.2787,  0.3654, -0.3871, -0.4004, -0.5770,
         -0.5783, -0.5099,  0.1701,  0.6484, -0.3855,  0.3513, -0.6546, -0.1442,
          0.3375,  0.6092,  0.6562,  0.2196, -0.2621,  0.5961,  0.0365, -0.8509,
          0.2126, -0.2714, -0.4352,  0.1094, -0.2154,  0.3926, -0.0332, -0.1840,
          0.5497, -0.1100, -0.0759, -0.3137,  0.2223,  0.4842,  0.0987,  0.3139,
          0.1311, -0.0049,  0.6346, -0.0560,  0.4097, -0.1529,  0.3432,  0.1707,
          0.5594,  0.4282, -0.5984, -0.2906, -0.2350,  0.4346, -0.1624, -0.3648,
          0.0806, -0.4837, -0.1838,  0.2907,  0.5554, -0.2107,  0.8758, -0.5081,
         -0.6954,  0.1758,  0.3275, -0.2483,  0.0825, -0.5925, -0.5288,  0.6715,
          0.7114, -0.3897,  0.1749,  0.0821, -0.0674,  0.4360,  0.1972, -0.0144,
          0.0274, -0.2965, -0.4467,  0.5524,  0.1397,  0.1328,  0.0478, -0.6188,
          0.3650, -0.0631, -0.6781,  0.0217,  0.2101,  0.1072, -0.4795, -0.3015,
          0.3204,  0.1700,  0.1979,  0.1604,  0.4727, -0.4869,  0.0566,  0.1891,
         -0.1973, -0.2870,  0.0397, -0.5887, -0.0466, -0.3947,  0.8023,  0.4126,
          0.5232,  0.0450, -0.5126, -0.4416,  0.3874, -0.3735, -0.6399,  0.7328,
         -0.4096,  0.5156, -0.2326,  0.6683, -0.2703,  0.7096, -0.8355, -0.1356,
          0.1928, -0.3296,  0.7817,  0.1597, -0.2067,  0.1519,  0.4048, -0.4178,
          0.7199, -0.5585,  0.2601,  0.0848,  0.1659,  0.0618, -0.1055, -0.6055,
         -0.7462,  0.4252,  0.1319,  0.4305, -0.6642, -0.7635, -0.1981,  0.0259,
         -0.5685, -0.2957, -0.5199,  0.3353,  0.3144, -0.3795, -0.0790, -0.7635,
         -0.1689, -0.0017,  0.5231,  0.3009,  0.4081, -0.1392, -0.0795,  0.0975,
          0.1018, -0.1667,  0.5026,  0.3285, -0.4062,  0.2985, -0.2559, -0.0619,
          0.2136,  0.7565, -0.2840, -0.1584,  0.1353,  0.4525,  0.5850,  0.5191]],
       device='cuda:0', grad_fn=<TanhBackward0>)



# Ayat
## 1
=== Tokenisasi ===
Teks input      : Dengan nama Allah Yang Maha Pengasih, Maha Penyayang.
Token/subword   : ['[CLS]', 'dengan', 'nama', 'allah', 'yang', 'maha', 'pengasih', ',', 'maha', 'penyayang', '.', '[SEP]']
Token IDs       : [2, 79, 712, 763, 34, 4262, 24896, 30468, 4262, 20900, 30470, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 12]) → [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 12, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [-0.3103,  0.0476, -0.2136,  0.5747, -0.5802,  0.3460, -0.4193,  0.1167,
          0.2573, -0.4526,  0.1514, -0.0981, -0.3991, -0.4193, -0.2804, -0.7975,
          0.6950,  0.4902, -0.4850,  0.4661,  0.1072,  0.3930,  0.3746,  0.4349,
          0.2037, -0.2722, -0.2832,  0.3372,  0.6899, -0.0186, -0.5194, -0.1102,
         -0.1236, -0.3300, -0.2468, -0.5211,  0.1951, -0.1522, -0.3664, -0.2216,
          0.1474,  0.7370, -0.2054,  0.1046, -0.5949, -0.1824, -0.3134, -0.4164,
          0.3121, -0.4304,  0.1923,  0.1614, -0.0977, -0.1498,  0.4054,  0.3014,
         -0.1037,  0.5202, -0.3706, -0.3481, -0.3562, -0.4616, -0.2310, -0.6271,
         -0.0459, -0.8212, -0.6108,  0.1246, -0.7267, -0.1515,  0.6396,  0.4990,
          0.0490,  0.6834, -0.2039, -0.4276,  0.2823, -0.4554, -0.0534, -0.4972,
         -0.8492, -0.1401, -0.3377,  0.1592, -0.2054,  0.0566, -0.8531, -0.3593,
          0.5321,  0.6889,  0.3784,  0.3347,  0.2432, -0.0972,  0.3854, -0.3708,
          0.2495, -0.3846,  0.2550, -0.3314, -0.8410, -0.5123,  0.3967, -0.0124,
          0.2208, -0.1800,  0.2936, -0.2739, -0.1866, -0.3283, -0.3848,  0.7155,
         -0.4001, -0.4846,  0.0314, -0.1027,  0.1652,  0.1319,  0.4958, -0.3273,
          0.1411, -0.2715, -0.5429, -0.2041, -0.3245,  0.7195, -0.0788, -0.3941,
         -0.2630,  0.0556,  0.0020,  0.0850, -0.3595, -0.6172, -0.7298,  0.5079,
          0.1488,  0.7790, -0.3360,  0.5690,  0.1324,  0.5367,  0.0444,  0.2941,
         -0.2000,  0.1935,  0.1160, -0.3222,  0.0759,  0.1587,  0.4194, -0.5331,
         -0.2364, -0.0045, -0.1758,  0.4004,  0.2727,  0.1961,  0.6531, -0.4513,
          0.1428, -0.1531, -0.2829, -0.5357, -0.3622, -0.1530,  0.4619,  0.0496,
         -0.3807, -0.3306,  0.5029,  0.0985, -0.0263, -0.4450,  0.3201, -0.1609,
          0.6050, -0.5999, -0.1107, -0.4233, -0.7060,  0.2489,  0.1607,  0.1865,
         -0.6132, -0.1194, -0.1325, -0.1366, -0.5400,  0.2388,  0.2069,  0.3976,
          0.1237,  0.0049,  0.0412,  0.4622,  0.0798, -0.4604,  0.1915,  0.2076,
          0.8253, -0.2008,  0.3753, -0.2360, -0.7299, -0.0566, -0.3731, -0.1028,
         -0.3411,  0.3773,  0.4942, -0.2714,  0.4674, -0.1500, -0.3011, -0.3710,
         -0.6208,  0.0400,  0.1546,  0.4933, -0.3483, -0.3876,  0.4537, -0.7006,
         -0.1785,  0.3765, -0.5896,  0.5015, -0.0720, -0.5077,  0.1684, -0.7848,
          0.1979,  0.1427, -0.4470,  0.6244, -0.3224, -0.2725, -0.4245, -0.5136,
          0.0288, -0.5079, -0.2640, -0.0887,  0.0075,  0.2964,  0.5466, -0.1133,
         -0.2745,  0.1009, -0.3991, -0.0857,  0.3399,  0.4483, -0.5538,  0.2156]],
       device='cuda:0', grad_fn=<TanhBackward0>)

## 2
=== Tokenisasi ===
Teks input      : Segala puji bagi Allah, Tuhan seluruh alam,
Token/subword   : ['[CLS]', 'segala', 'puji', 'bagi', 'allah', ',', 'tuhan', 'seluruh', 'alam', ',', '[SEP]']
Token IDs       : [2, 1517, 11785, 396, 763, 30468, 1251, 969, 668, 30468, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 11]) → [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 11, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [-0.1118,  0.2192, -0.2960,  0.4788, -0.7621,  0.1665, -0.2101,  0.0468,
         -0.0576,  0.3146, -0.4167, -0.0038,  0.1315, -0.2071,  0.5064, -0.6959,
          0.7538,  0.3173, -0.3162,  0.4850,  0.1477,  0.5050,  0.4545,  0.4838,
          0.7024, -0.7892, -0.5384,  0.4797,  0.6463,  0.1944, -0.4105, -0.2306,
          0.1636, -0.2233, -0.2160, -0.2420,  0.1865,  0.1888, -0.0148, -0.1862,
          0.2523,  0.5620, -0.3453, -0.0604, -0.1914,  0.5446, -0.2229, -0.3905,
          0.1968,  0.0662, -0.0894,  0.0696,  0.3504, -0.0283, -0.1431,  0.0284,
         -0.2920,  0.5257,  0.0982, -0.1049, -0.6722,  0.0466, -0.1632, -0.5122,
          0.5080, -0.8638, -0.5768,  0.2112, -0.4722,  0.1864, -0.2772,  0.3545,
         -0.1582,  0.6374,  0.0041, -0.2694,  0.3862, -0.3883,  0.1273, -0.2892,
         -0.5856, -0.0208, -0.3854, -0.6048,  0.0818,  0.3567, -0.7679, -0.1688,
          0.0881,  0.5357,  0.1106, -0.0904,  0.5741,  0.0436, -0.0236,  0.1551,
         -0.2781, -0.0231,  0.1408,  0.2670, -0.5603, -0.2964,  0.2092, -0.2488,
          0.2489, -0.1031, -0.2232, -0.3578, -0.1726, -0.0676, -0.1120,  0.4475,
          0.2269, -0.0339, -0.0960,  0.1035,  0.3796,  0.4218,  0.1487, -0.1386,
          0.1331, -0.4421,  0.0130,  0.1805, -0.1954,  0.4018,  0.4416, -0.4255,
         -0.2756, -0.3152,  0.2679, -0.0106, -0.3759, -0.8256, -0.2725,  0.5793,
          0.1335,  0.5917, -0.0902,  0.6699, -0.0747,  0.5509,  0.7532,  0.3897,
         -0.3841,  0.1746,  0.4488, -0.4341,  0.5979,  0.1751,  0.2021, -0.6452,
         -0.4575, -0.3662,  0.1287,  0.0763,  0.0479, -0.0934,  0.2883, -0.3809,
         -0.1978,  0.1973, -0.5246, -0.8512, -0.4773,  0.7052,  0.1317,  0.3026,
          0.0081, -0.4065,  0.5882,  0.1901, -0.1160, -0.5694,  0.5523,  0.2615,
          0.3705, -0.4844,  0.0686, -0.4778, -0.6441,  0.0130,  0.2648, -0.2128,
         -0.8166, -0.2126,  0.2825, -0.6627,  0.0073,  0.2371, -0.1082,  0.4877,
          0.0423, -0.3396,  0.4433,  0.5607,  0.0899,  0.3264,  0.3934, -0.0335,
          0.9065, -0.1359,  0.3561, -0.5667, -0.5211, -0.2047,  0.1827, -0.2875,
         -0.4563, -0.5265,  0.3494, -0.5153,  0.3713,  0.3783, -0.7844, -0.2715,
         -0.2399,  0.5631,  0.2931,  0.2419, -0.0782, -0.4940,  0.1441, -0.5709,
          0.1346,  0.5145,  0.0628,  0.6529,  0.1786, -0.3410,  0.1731, -0.7807,
         -0.1738,  0.1119, -0.4308,  0.6414, -0.5614, -0.3973, -0.4898, -0.2962,
          0.1126, -0.3772, -0.3905, -0.2554,  0.0287,  0.1342,  0.4392,  0.6396,
         -0.5590,  0.5235, -0.4887, -0.6730,  0.0180, -0.1956, -0.5777, -0.2125]],
       device='cuda:0', grad_fn=<TanhBackward0>)

## 3
=== Tokenisasi ===
Teks input      : Yang Maha Pengasih, Maha Penyayang,
Token/subword   : ['[CLS]', 'yang', 'maha', 'pengasih', ',', 'maha', 'penyayang', ',', '[SEP]']
Token IDs       : [2, 34, 4262, 24896, 30468, 4262, 20900, 30468, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 9]) → [1, 1, 1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 9, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [-0.5673, -0.1202, -0.1130,  0.5764, -0.6153,  0.3180, -0.3095,  0.0135,
          0.0303, -0.4690,  0.0508, -0.2876, -0.5690, -0.5175, -0.4505, -0.7430,
          0.5285,  0.5633, -0.2743,  0.4326,  0.4732,  0.4141,  0.3057,  0.6341,
          0.2349,  0.0803, -0.6045,  0.3173,  0.3508, -0.0837, -0.6933, -0.1233,
          0.1175, -0.2177, -0.1615, -0.5192, -0.0755, -0.1549, -0.6825, -0.3037,
          0.0898,  0.7016,  0.0504,  0.1470, -0.6168, -0.2226, -0.2309, -0.2831,
          0.4857, -0.4552,  0.2352, -0.0941,  0.2087, -0.3731,  0.4583,  0.5732,
         -0.0391,  0.7623, -0.4298, -0.3146,  0.0306, -0.1843, -0.1308, -0.7692,
          0.1887, -0.8548, -0.3846,  0.1380, -0.7071, -0.3205,  0.4562,  0.4150,
          0.2023,  0.5124, -0.4977, -0.3601,  0.0430, -0.3779, -0.3460, -0.5144,
         -0.8101, -0.2897, -0.3387,  0.3703,  0.2313,  0.1665, -0.8929, -0.3970,
          0.4561,  0.6932,  0.4860,  0.2623,  0.4867, -0.1348,  0.4441, -0.4598,
          0.1782, -0.2338, -0.0223, -0.2659, -0.8182, -0.4658,  0.3684,  0.0821,
          0.3154, -0.3580,  0.1453, -0.4533, -0.0095, -0.5938, -0.2461,  0.7823,
         -0.1685, -0.3398,  0.2967, -0.4223,  0.0996,  0.4001,  0.4197, -0.3262,
          0.1417, -0.0712, -0.5570, -0.1245, -0.2889,  0.7602, -0.0316, -0.4342,
         -0.1717, -0.0022, -0.0605, -0.0211, -0.2635, -0.3879, -0.6549,  0.2143,
          0.0047,  0.8128, -0.0526,  0.6068, -0.0503,  0.4721, -0.1646,  0.3133,
         -0.5248,  0.2194, -0.1495, -0.2159, -0.0334,  0.1730,  0.5602, -0.4998,
         -0.1989,  0.2712,  0.1760,  0.2366, -0.0134, -0.0570,  0.5017, -0.6095,
         -0.2570,  0.0141, -0.2590, -0.3323, -0.2788,  0.1401,  0.1681, -0.3026,
         -0.5291, -0.3981,  0.5301,  0.0846, -0.0377, -0.3317,  0.4417, -0.1209,
          0.5419, -0.7181, -0.3452, -0.4111, -0.7638, -0.0190,  0.2651, -0.0281,
         -0.4836, -0.2173,  0.1091, -0.3389, -0.3465,  0.1103,  0.5393,  0.2793,
         -0.0782, -0.0845,  0.1069,  0.1181,  0.0099, -0.6702,  0.1413,  0.3140,
          0.8262, -0.0856,  0.2036, -0.2492, -0.6549, -0.3325, -0.4460, -0.4399,
         -0.2150,  0.3607,  0.3495, -0.0638,  0.0845, -0.0749, -0.2795, -0.2492,
         -0.4709,  0.0975,  0.1411,  0.4706, -0.5603, -0.5438,  0.3094, -0.7088,
         -0.3239,  0.4863, -0.4184,  0.4739, -0.1573, -0.7112, -0.2070, -0.6915,
          0.3376,  0.2971, -0.1681,  0.1311, -0.2662, -0.0901, -0.2835, -0.5351,
         -0.1493, -0.4926, -0.2774, -0.1672,  0.0506,  0.2695,  0.3924,  0.1155,
         -0.2681,  0.0636, -0.3518, -0.3566,  0.2676,  0.3864, -0.3633,  0.3107]],
       device='cuda:0', grad_fn=<TanhBackward0>)

## 4
=== Tokenisasi ===
Teks input      : Pemilik hari pembalasan.
Token/subword   : ['[CLS]', 'pemilik', 'hari', 'pembalasan', '.', '[SEP]']
Token IDs       : [2, 2799, 406, 28020, 30470, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 6]) → [1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 6, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [-2.3307e-01,  2.6634e-01, -2.0715e-01, -6.4734e-01, -4.1098e-01,
          2.6832e-01, -4.1373e-01, -7.4388e-03,  4.7492e-01,  1.7216e-01,
         -2.0702e-01, -6.6863e-01, -5.2029e-01, -3.5179e-01, -2.8710e-01,
         -4.1970e-01,  4.1387e-01, -2.5703e-01, -1.1806e-02,  5.5689e-01,
          7.0374e-01,  7.3004e-01, -5.5226e-01, -4.9019e-03, -5.0586e-01,
          2.5122e-01, -7.0860e-01, -4.1030e-01,  4.1404e-01,  1.7157e-01,
          2.2779e-01, -7.2424e-01,  1.0411e-01, -2.2042e-01, -1.2390e-01,
         -8.2355e-01,  4.8420e-01,  1.4588e-01, -4.9681e-01,  6.4576e-01,
          3.6724e-01,  6.1995e-01, -8.6575e-04, -1.5692e-01, -3.5595e-01,
         -1.0632e-01,  3.6732e-01, -2.3576e-01,  4.3289e-01, -6.5333e-01,
         -3.1111e-01,  2.6785e-01,  4.2128e-01,  1.7869e-01,  5.9300e-01,
          2.8388e-01, -5.1043e-01,  1.7562e-01, -2.1076e-01,  1.0798e-01,
          6.2988e-02, -6.0804e-01, -5.5334e-02, -2.8373e-01, -1.6183e-02,
          1.9654e-01, -2.8540e-01,  1.1333e-03, -8.0016e-01,  6.8353e-02,
         -6.5263e-01,  8.7020e-02,  5.0826e-01, -7.0107e-01,  2.7013e-01,
         -4.6065e-02, -4.2301e-01, -5.5192e-01, -9.0940e-03,  6.3415e-01,
          5.3131e-02,  3.6766e-01,  7.4586e-01,  7.1380e-01, -5.1404e-03,
         -4.1330e-01, -5.3544e-01, -5.4817e-01,  3.1970e-01,  6.2511e-01,
          5.1484e-02,  5.0807e-01,  4.0545e-01, -2.1795e-02,  4.4807e-01,
         -2.8507e-01,  6.7964e-01, -6.2147e-01,  1.7899e-01, -8.0114e-01,
         -5.0861e-01, -4.0470e-01, -4.1857e-01, -3.8224e-02,  7.6989e-02,
          5.0185e-02,  5.2904e-01, -4.1717e-01,  1.8402e-01, -5.0901e-01,
         -9.6681e-03,  8.7703e-01, -1.8447e-01,  3.3402e-01, -2.5481e-01,
         -2.5759e-01,  8.1296e-01,  4.4759e-01,  3.8135e-01, -6.5074e-01,
          1.0371e-01, -5.6821e-01, -4.8504e-01, -4.6297e-01,  2.2420e-01,
         -3.3957e-01, -3.7988e-01,  2.9223e-01,  4.0181e-02,  1.9817e-01,
         -2.4853e-01, -4.5447e-01, -1.4830e-01,  9.5384e-03,  3.6268e-01,
         -2.8031e-01, -1.5279e-01,  2.5372e-01, -2.1293e-01,  7.6717e-01,
          2.5042e-01, -3.6549e-01, -1.7176e-01,  8.2445e-02, -8.1525e-02,
         -2.9613e-01,  3.1422e-01, -5.5729e-01, -1.0114e-01,  6.5779e-01,
          5.9879e-01, -7.3145e-01,  1.3047e-01, -4.7175e-01, -5.3993e-01,
          7.8937e-01, -1.6453e-01,  3.2971e-01,  4.9404e-01, -1.5013e-01,
          6.8876e-02, -4.1183e-01, -1.5261e-04,  2.5581e-01, -2.3113e-02,
         -8.9406e-02,  1.7556e-01, -4.1408e-01,  5.9222e-01, -4.2889e-01,
          2.4764e-01, -1.1869e-01,  7.3156e-02, -3.9889e-01,  4.4312e-01,
         -8.2694e-01,  6.8458e-01, -5.0606e-01, -2.3057e-01, -7.3850e-01,
          1.4296e-01, -4.8204e-01,  1.9536e-01, -2.0761e-01,  1.1083e-01,
         -8.8181e-03,  1.6916e-02,  1.7533e-02,  2.3427e-01, -2.1648e-01,
          1.7499e-01, -4.0948e-01, -7.0187e-01,  5.0085e-01, -3.4869e-01,
          4.3425e-01,  5.0499e-02,  5.2036e-01,  4.0358e-01, -1.7535e-01,
         -1.0303e-01,  1.9468e-01,  3.4952e-01, -4.6284e-01, -5.1974e-01,
          4.4921e-01,  3.8392e-01,  2.8937e-01,  6.6168e-01, -5.6670e-01,
         -1.4180e-01, -8.6685e-02,  7.6121e-01, -1.0305e-01,  2.9358e-01,
         -4.8195e-01, -2.7152e-01, -3.9649e-01, -1.9855e-01,  5.9278e-01,
         -3.9235e-01, -4.9118e-01, -2.9255e-01, -3.5709e-01,  1.8512e-01,
          2.3437e-01,  1.4430e-01, -2.4156e-01, -3.6157e-01, -5.1439e-01,
          7.1667e-02,  1.9794e-02,  3.9987e-01,  4.0767e-01,  1.9286e-01,
          4.9713e-01,  9.8848e-02, -3.0112e-01, -4.4737e-01, -1.8412e-01,
         -2.5080e-01, -3.0692e-01, -6.3826e-02, -9.4105e-02,  9.6749e-02,
          4.9961e-01,  5.3139e-01, -5.9991e-01,  6.1034e-01, -4.8643e-01,
         -1.8369e-01,  1.7868e-01,  2.8055e-01,  2.6068e-01, -2.2664e-01,
          1.7952e-01]], device='cuda:0', grad_fn=<TanhBackward0>)

## 5
=== Tokenisasi ===
Teks input      : Hanya kepada Engkaulah kami menyembah dan hanya kepada Engkaulah kami mohon pertolongan.
Token/subword   : ['[CLS]', 'hanya', 'kepada', 'engkau', '##lah', 'kami', 'menyembah', 'dan', 'hanya', 'kepada', 'engkau', '##lah', 'kami', 'mohon', 'pertolongan', '.', '[SEP]']
Token IDs       : [2, 344, 455, 4010, 212, 321, 12848, 41, 344, 455, 4010, 212, 321, 2903, 9019, 30470, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 17]) → [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 17, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [ 0.4065,  0.1063,  0.1616,  0.2294, -0.4373, -0.2822, -0.1539,  0.3683,
         -0.2704, -0.1221, -0.0971, -0.0678, -0.3834, -0.4054,  0.3756, -0.7038,
          0.6236,  0.7217, -0.2920,  0.5209,  0.0093,  0.6557,  0.5103, -0.4935,
          0.5767,  0.1039,  0.1009, -0.1774,  0.4309, -0.4300, -0.7471, -0.4129,
         -0.0754, -0.1010, -0.4352, -0.5438, -0.0254,  0.4039, -0.5197,  0.1384,
          0.7002,  0.6187, -0.4479,  0.0047, -0.6166,  0.3163, -0.2002, -0.1407,
          0.5657, -0.2511,  0.0643,  0.2293,  0.2807,  0.4300,  0.0268,  0.3912,
         -0.1991,  0.4354,  0.0483, -0.6954, -0.1035, -0.0275,  0.1595,  0.0577,
          0.2013, -0.7131, -0.0541,  0.4071, -0.8152, -0.1310,  0.0345,  0.4189,
          0.1616,  0.6513, -0.2982, -0.4131,  0.4431, -0.3203,  0.1336, -0.0726,
         -0.0120, -0.5133,  0.2774,  0.5546, -0.1638,  0.6215, -0.6556, -0.4518,
          0.5212,  0.5032,  0.6115,  0.4897,  0.2693,  0.0125,  0.0336,  0.2728,
         -0.2888, -0.2205,  0.1021, -0.1518, -0.6249, -0.5542,  0.3614, -0.3594,
         -0.3011, -0.2169,  0.1601, -0.5069, -0.6635,  0.0255, -0.4836,  0.6794,
          0.4227,  0.3801,  0.3174, -0.2936,  0.4396, -0.1882,  0.4904,  0.0969,
         -0.3021, -0.4927, -0.6299,  0.0021, -0.4946,  0.4517,  0.0484, -0.5619,
         -0.2929, -0.4575,  0.2645, -0.4232,  0.0404, -0.7398, -0.1395,  0.6439,
          0.4201,  0.2987, -0.4498,  0.3947,  0.0647,  0.4533,  0.2825,  0.1941,
          0.0183,  0.4034,  0.2805, -0.4821,  0.4514,  0.3211, -0.3168, -0.3975,
         -0.5419, -0.4018,  0.0073,  0.3125,  0.6448,  0.2899,  0.4451,  0.0189,
         -0.1708, -0.2227,  0.0097, -0.4601, -0.3243,  0.5678,  0.0558, -0.4313,
          0.0513, -0.0733, -0.2842, -0.2632, -0.2501, -0.6658,  0.6220,  0.2982,
          0.6191, -0.4688,  0.1886, -0.0520, -0.0983,  0.2813,  0.3111, -0.1846,
         -0.7065, -0.3534,  0.0850, -0.2468, -0.0241,  0.1137, -0.8212,  0.0249,
          0.0769, -0.1313,  0.2448,  0.6883,  0.2053,  0.0955, -0.0906, -0.0862,
          0.8628,  0.2315,  0.4039, -0.5162, -0.9184, -0.3290, -0.4352,  0.0484,
         -0.1464, -0.6418, -0.0365, -0.2246,  0.1538,  0.3944, -0.6114, -0.3298,
         -0.6579,  0.0533,  0.3659,  0.3405,  0.2209, -0.1111, -0.4284, -0.2309,
         -0.2256, -0.3507, -0.4826,  0.7370, -0.1363, -0.6269,  0.3836, -0.7654,
         -0.4513, -0.3562,  0.2303,  0.6308, -0.6398, -0.3436, -0.5654, -0.5749,
          0.5575, -0.6239, -0.3737, -0.5680, -0.1952,  0.4537,  0.6205,  0.3077,
         -0.5378,  0.3190, -0.4773, -0.1446,  0.1615,  0.6025, -0.2365,  0.3673]],
       device='cuda:0', grad_fn=<TanhBackward0>)

## 6
=== Tokenisasi ===
Teks input      : Tunjukilah kami jalan yang lurus,
Token/subword   : ['[CLS]', 'tunjuk', '##ilah', 'kami', 'jalan', 'yang', 'lurus', ',', '[SEP]']
Token IDs       : [2, 23450, 761, 321, 795, 34, 5971, 30468, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 9]) → [1, 1, 1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 9, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [ 5.2651e-01, -6.0712e-02,  5.9696e-02,  4.5273e-01, -4.5468e-01,
          1.5651e-01, -3.9187e-01,  5.1894e-01,  2.3290e-01, -5.9411e-01,
          2.6324e-01, -7.3232e-02,  1.3829e-01, -8.0145e-01,  4.3199e-01,
         -5.0432e-01,  4.7855e-01,  2.1610e-01, -8.0023e-01,  5.1392e-01,
          2.8046e-01,  4.4983e-01, -3.6106e-01, -3.0448e-01,  4.8598e-02,
          1.2434e-02, -2.3647e-01, -3.3060e-01, -1.6457e-01,  2.1278e-01,
         -5.3009e-01, -3.2178e-02,  2.4393e-01,  1.4763e-02, -1.2645e-01,
         -6.6704e-01,  6.5300e-01,  4.0549e-02, -3.9303e-02, -2.1112e-01,
          6.7920e-01,  3.3587e-01, -5.6487e-01,  4.4198e-01, -5.1107e-01,
          8.1366e-02, -1.2146e-01, -3.9646e-01,  1.8181e-01, -8.1238e-01,
         -8.9729e-02, -1.5094e-01, -3.4810e-01,  3.7030e-02,  2.6767e-01,
         -2.6404e-01, -8.0263e-01, -1.1755e-01, -3.2760e-01, -1.0396e-01,
          3.5698e-01,  6.3765e-01, -1.6343e-01, -4.8934e-01,  4.1637e-02,
         -5.8942e-01,  2.8947e-01, -2.0837e-01, -4.9561e-01,  3.0894e-01,
          6.1206e-01,  1.6156e-01,  1.4496e-01,  6.5901e-01,  6.2486e-01,
          5.2632e-02,  3.3845e-01, -4.9177e-01, -2.3207e-01, -5.6213e-01,
         -6.0809e-01, -5.9942e-01, -4.4127e-02,  4.7081e-01, -4.8631e-01,
          7.4532e-01, -7.3941e-01, -7.1342e-02,  4.3209e-01,  3.3255e-01,
          7.1099e-01, -5.5084e-03, -1.9531e-01,  5.0413e-01,  4.3583e-01,
         -5.3674e-01, -3.7577e-01, -4.1653e-01, -2.0488e-01,  1.8107e-01,
         -4.0772e-01, -4.7439e-01,  3.3386e-01, -5.0344e-01,  4.5954e-01,
         -2.6362e-01, -1.0566e-01, -4.8927e-01, -3.9418e-01,  3.5377e-01,
         -1.9879e-01,  6.5630e-01, -1.7434e-02,  1.1009e-01,  7.7857e-01,
         -2.1018e-01,  3.9345e-01,  7.3721e-02,  4.4308e-01,  3.6003e-01,
          4.3205e-01,  8.1939e-02, -4.4292e-01, -3.7805e-01, -5.5502e-01,
          2.7074e-01, -1.2910e-01, -3.1836e-01,  8.0674e-02, -5.7865e-01,
         -1.6053e-02, -8.1955e-03,  2.5935e-01, -2.2829e-01,  6.2589e-01,
         -1.5143e-01, -4.6563e-01,  6.8856e-01,  6.7509e-01,  5.2568e-02,
          2.9107e-01, -4.1574e-01,  2.8050e-01,  8.7389e-01,  7.9345e-01,
         -3.1897e-01,  5.4326e-01,  1.4434e-02, -1.7941e-01,  3.7426e-01,
         -1.6389e-01, -1.3935e-01,  8.3705e-03, -1.5058e-01, -3.7390e-01,
          8.1671e-01,  2.3984e-01, -1.0273e-01, -3.9194e-02, -9.7498e-02,
          4.0217e-01,  9.9958e-02, -5.4437e-01, -2.6848e-01,  2.5613e-01,
          3.2357e-01, -3.5236e-01, -4.1310e-01, -2.2845e-01,  2.3362e-01,
         -5.6921e-01,  1.2787e-03,  3.1779e-01, -6.7945e-01,  6.0796e-01,
          7.9409e-02,  3.3616e-01,  3.4680e-01,  3.1525e-01, -4.6564e-01,
         -5.8875e-01, -1.0020e-01,  8.2857e-01,  1.1341e-01,  1.1921e-01,
         -1.6308e-01, -5.1721e-01, -3.9165e-01,  5.5545e-01, -2.2786e-01,
         -7.1258e-01,  2.9348e-01,  6.2504e-02, -1.0174e-01,  2.3415e-01,
          5.4581e-01,  6.1022e-01,  4.8226e-01, -7.2527e-01, -2.1944e-01,
          5.0191e-01, -4.2662e-01,  7.0642e-01,  2.0507e-01, -3.0967e-01,
          4.0089e-01,  7.5264e-02, -1.7594e-02,  7.1905e-01, -6.5224e-01,
          4.4529e-01, -2.7248e-01, -7.2451e-02, -2.4491e-01, -4.9487e-01,
         -3.6521e-01, -8.3110e-01, -3.3202e-01,  1.6882e-01,  1.6214e-01,
         -4.5817e-01, -8.3023e-01, -9.6563e-02, -2.1761e-01, -5.2196e-01,
         -3.2112e-01, -2.3664e-01,  5.4729e-01,  1.3365e-01, -6.2081e-01,
          1.7688e-01, -7.8347e-01, -5.6805e-01, -9.3056e-02,  4.7720e-01,
          3.4865e-03, -7.5327e-02,  2.2281e-01,  4.4981e-04, -4.4990e-01,
         -1.6066e-03, -2.0831e-01, -1.4735e-01,  3.2818e-01, -5.5353e-01,
          6.7969e-01, -2.3477e-01,  1.3553e-01, -1.2833e-01,  8.7120e-01,
         -1.7322e-01, -1.7313e-01,  2.0026e-02,  4.9372e-01,  1.2998e-01,
          6.2645e-01]], device='cuda:0', grad_fn=<TanhBackward0>)

## 7
=== Tokenisasi ===
Teks input      : (yaitu) jalan orang-orang yang telah Engkau beri nikmat kepadanya; bukan (jalan) mereka yang dimurkai, dan bukan (pula jalan) mereka yang sesat.
Token/subword   : ['[CLS]', '(', 'yaitu', ')', 'jalan', 'orang', '-', 'orang', 'yang', 'telah', 'engkau', 'beri', 'nikmat', 'kepadanya', ';', 'bukan', '(', 'jalan', ')', 'mereka', 'yang', 'dim', '##ur', '##ka', '##i', ',', 'dan', 'bukan', '(', 'pula', 'jalan', ')', 'mereka', 'yang', 'sesat', '.', '[SEP]']
Token IDs       : [2, 30464, 451, 30465, 795, 232, 30469, 232, 34, 351, 4010, 5030, 5748, 4822, 30473, 531, 30464, 795, 30465, 267, 34, 369, 58, 3331, 30356, 30468, 41, 531, 30464, 1355, 795, 30465, 267, 34, 11736, 30470, 3]

=== Representasi ===
Attention Mask      : torch.Size([1, 37]) → [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Token Embeddings    : torch.Size([1, 37, 1024])
Pooled Embedding    : torch.Size([1, 1024])
Projected Embedding : torch.Size([1, 256])
Encoded             : tensor([
        [-5.0671e-02, -7.5922e-02, -1.1781e-01, -1.0164e-01, -1.1342e-01,
         -1.7007e-01, -8.7608e-02, -9.8443e-02,  6.5899e-02, -4.3686e-01,
          3.6966e-01, -3.7810e-02,  7.8424e-02, -2.9852e-01, -3.5765e-01,
         -5.9863e-01,  8.1764e-01,  1.5477e-01, -4.1712e-01,  2.6955e-01,
          1.5035e-01,  5.3343e-01, -4.2139e-01,  4.2296e-01,  4.5461e-03,
         -4.9267e-01, -3.2428e-01,  1.7645e-02,  3.3335e-01,  1.4997e-01,
          9.8767e-02, -2.4683e-01,  9.6427e-02, -1.3561e-01, -1.8422e-01,
         -6.1736e-01,  6.2808e-01,  2.5010e-01, -5.1417e-01,  2.5661e-01,
          6.9220e-01,  5.9117e-01, -3.2509e-01,  2.7549e-02, -5.3322e-01,
          1.7598e-01, -3.4904e-01, -5.3102e-01, -1.9544e-01, -3.4134e-01,
          3.7047e-01, -2.0190e-01, -3.6166e-01, -2.6239e-02,  3.3178e-01,
         -3.1359e-01, -5.2569e-02, -3.6955e-03, -2.8546e-01, -3.6667e-01,
          3.8997e-01, -3.8436e-01, -4.2178e-01, -2.4178e-01,  1.9862e-01,
         -7.9900e-01,  1.4980e-01, -8.8887e-01, -1.2794e-01,  1.6089e-02,
          1.5499e-01,  3.2741e-01,  5.7133e-01,  7.0970e-01,  4.7984e-01,
         -2.6541e-01,  2.3682e-01, -2.1387e-01, -1.5164e-01, -6.1697e-01,
         -5.2878e-01, -5.0333e-02,  3.2307e-01,  4.4694e-01, -1.3167e-01,
          6.5905e-01, -8.1375e-01, -4.9744e-01,  2.4163e-01,  1.5503e-01,
          4.9814e-01,  4.2702e-01, -3.2126e-01,  4.4045e-01,  5.9196e-01,
         -4.1772e-01, -1.8638e-01, -3.9474e-01,  4.8081e-02,  4.2238e-01,
          8.2127e-02,  8.6406e-02,  2.0643e-01, -8.6023e-01,  6.4356e-03,
         -5.9688e-01, -4.3868e-01, -5.3378e-02,  3.9671e-01,  9.0117e-02,
         -3.8926e-01,  7.6903e-01,  4.8077e-01,  4.0775e-01,  5.6695e-01,
          1.1153e-01, -2.2937e-01, -3.6012e-02,  1.4832e-01,  4.8576e-01,
          2.8754e-01, -1.2395e-01,  1.5923e-01,  8.4744e-02, -4.2685e-01,
         -9.6325e-02, -1.1779e-01, -1.1457e-01, -4.9644e-01, -8.5105e-01,
         -5.4364e-02,  1.7032e-01,  6.4006e-01, -4.7682e-01,  5.8605e-01,
          1.7289e-01, -5.1172e-04,  6.1761e-01,  1.8291e-02,  4.0868e-02,
         -1.1870e-02, -6.0859e-01,  3.9850e-01,  6.6378e-01,  2.7524e-01,
         -2.6683e-01,  2.9270e-01,  6.7674e-01,  5.8332e-01,  2.5643e-01,
          3.3067e-02,  2.7753e-01,  7.6251e-02, -3.2228e-01, -1.6215e-01,
          5.0564e-01,  3.0004e-02,  4.4517e-01,  2.9307e-01,  2.1298e-01,
          1.2547e-01,  4.7397e-01, -2.6730e-01, -6.4700e-01, -2.3639e-01,
          4.9636e-01, -2.3232e-01, -7.0030e-01, -9.6677e-02,  4.1097e-01,
         -5.1807e-02,  8.1973e-02, -4.5773e-01, -2.5976e-01,  2.8828e-01,
         -4.3402e-02,  6.9261e-02,  1.8431e-01, -2.8558e-01, -3.0641e-01,
         -4.5345e-01, -1.8545e-01,  5.1316e-01,  2.9291e-01,  3.5884e-01,
          3.2631e-01, -3.6849e-01, -4.2903e-01,  3.5573e-01, -3.6544e-02,
         -6.8917e-01, -6.2243e-03,  2.8325e-01, -2.2074e-01,  1.7492e-01,
          1.9530e-01,  7.2480e-01,  5.8594e-01, -6.2480e-01,  4.6548e-01,
          8.3372e-02, -1.6912e-01,  7.3560e-01,  3.0698e-02, -2.0964e-01,
         -7.4172e-02, -2.2661e-01, -1.9187e-01,  6.1908e-01, -1.2394e-01,
         -1.8201e-02,  3.0755e-01,  7.2762e-01,  1.0612e-01, -6.0645e-01,
         -3.3114e-01, -6.2580e-01, -4.0113e-01,  1.8956e-01, -3.3678e-02,
         -2.3475e-01,  1.4453e-01, -9.2222e-02, -5.7321e-01, -5.3270e-01,
          2.4670e-02, -5.2194e-01,  2.9434e-01, -5.8004e-01, -7.4278e-01,
         -8.8757e-02, -5.8922e-01, -2.1766e-01, -3.5815e-01, -2.9794e-02,
          3.4712e-01,  5.4028e-01, -5.1702e-01, -4.6006e-01, -8.0986e-01,
          2.4879e-01, -4.9252e-01, -1.3329e-01, -1.2915e-01, -5.1411e-01,
          1.3453e-02, -3.9023e-01,  3.5777e-01,  9.9087e-02,  3.7081e-01,
         -4.3580e-01, -1.6727e-01,  2.2766e-01,  6.5399e-03,  1.2666e-02,
          2.2670e-01]], device='cuda:0', grad_fn=<TanhBackward0>)

